\relax 
\providecommand\hyper@newdestlabel[2]{}
\@writefile{toc}{\contentsline {chapter}{\numberline {第二章\hspace  {.3em}}无线信号调制识别以及深度学习理论}{9}{chapter.2}}
\@writefile{lof}{\addvspace {10.0pt}}
\@writefile{lot}{\addvspace {10.0pt}}
\newlabel{chap: mod_rec_deep_learning_theo}{{二}{9}{无线信号调制识别以及深度学习理论}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}引言}{9}{section.2.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}调制识别}{9}{section.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}调制信号}{9}{subsection.2.2.1}}
\newlabel{sec:mod_signal}{{2.2.1}{9}{调制信号}{subsection.2.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}调制信息}{9}{subsection.2.2.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}信道对调制信号的影响}{9}{subsection.2.2.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}神经网络概述}{10}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}神经元概述}{10}{subsection.2.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces 神经元示意图\relax }}{10}{figure.caption.14}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig_2_1}{{2.1}{10}{神经元示意图\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces $ReLU$函数\relax }}{11}{figure.caption.15}}
\newlabel{sec:fig_2_2}{{2.2}{11}{$ReLU$函数\relax }{figure.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces $Sigmoid$函数\relax }}{11}{figure.caption.15}}
\newlabel{sec:fig_2_3}{{2.3}{11}{$Sigmoid$函数\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}前馈神经网络}{11}{subsection.2.3.2}}
\newlabel{sec:fig_2_4}{{\caption@xref {sec:fig_2_4}{ on input line 72}}{12}{前馈神经网络}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces 前馈神经网络\relax }}{12}{figure.caption.16}}
\newlabel{fig_2_3}{{2.4}{12}{前馈神经网络\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}反向传播算法}{12}{subsection.2.3.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}卷积神经网络}{14}{section.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}卷积运算}{14}{subsection.2.4.1}}
\newlabel{sec:the_convolution_operation}{{2.4.1}{14}{卷积运算}{subsection.2.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}卷积特性}{15}{subsection.2.4.2}}
\newlabel{con_net}{{2.4.2}{15}{卷积特性}{subsection.2.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}卷积作为一种无限强的先验}{15}{subsection.2.4.3}}
\citation{Jarrett-ICCV2009-small,Saxe-ICML2011,pinto2011scaling,cox2011beyond}
\citation{Saxe-ICML2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.4}随机或无监督的特征}{16}{subsection.2.4.4}}
\newlabel{sec:random_or_unsupervised_features}{{2.4.4}{16}{随机或无监督的特征}{subsection.2.4.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}卷积自编码器}{16}{section.2.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces 自编码器\relax }}{17}{figure.caption.17}}
\newlabel{fig_2_5}{{2.5}{17}{自编码器\relax }{figure.caption.17}{}}
\citation{Graves-et-al-ICASSP2013,Pascanu-et-al-ICLR2014}
\newlabel{sec:eqt2_3}{{2-19}{18}{卷积自编码器}{equation.2.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}\glssymbol {LSTM}}{18}{section.2.6}}
\newlabel{sec:lstm}{{2.6}{18}{\glssymbol {LSTM}}{section.2.6}{}}
\newlabel{chap:sequence_modeling_recurrent_and_recursive_nets}{{2.6}{18}{\glssymbol {LSTM}}{section.2.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces \glssymbol {LSTM}\nobreakspace {}\gls {recurrent_network}``细胞''的框图。 细胞彼此循环连接，代替一般\gls {recurrent_network}中普通的\gls {hidden_unit}。 这里使用常规的人工神经元计算输入特征。 如果sigmoid输入门允许，它的值可以累加到状态。 状态单元具有线性自循环，其权重由\gls {forget_gate}控制。 细胞的输出可以被输出门关闭。 所有\gls {gated}单元都具有sigmoid非线性，而输入单元可具有任意的压缩非线性。 状态单元也可以用作\gls {gated}单元的额外输入。 黑色方块表示单个\gls {time_step}的延迟。 \relax }}{18}{figure.caption.18}}
\newlabel{fig:chapter2_lstm_cell}{{2.6}{18}{\glssymbol {LSTM}~\gls {recurrent_network}``细胞''的框图。 细胞彼此循环连接，代替一般\gls {recurrent_network}中普通的\gls {hidden_unit}。 这里使用常规的人工神经元计算输入特征。 如果sigmoid输入门允许，它的值可以累加到状态。 状态单元具有线性自循环，其权重由\gls {forget_gate}控制。 细胞的输出可以被输出门关闭。 所有\gls {gated}单元都具有sigmoid非线性，而输入单元可具有任意的压缩非线性。 状态单元也可以用作\gls {gated}单元的额外输入。 黑色方块表示单个\gls {time_step}的延迟。 \relax }{figure.caption.18}{}}
\citation{Bengio-trnn94,Hochreiter+Schmidhuber-1997,chapter-gradient-flow-2001}
\citation{Graves-book2012,Graves-arxiv2013,Sutskever-et-al-NIPS2014}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}神经网络优化算法}{20}{section.2.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}随机梯度下降优化算法}{20}{subsection.2.7.1}}
\newlabel{sec:stochastic_gradient_descent_chap8}{{2.7.1}{20}{\glsentrytext {SGD}优化算法}{subsection.2.7.1}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.1}{\ignorespaces \gls {SGD}（\glssymbol {SGD}）在第$k$个训练迭代的更新\relax }}{20}{algorithm.2.1}}
\newlabel{alg:sgd}{{2.1}{20}{\gls {SGD}（\glssymbol {SGD}）在第$k$个训练迭代的更新\relax }{algorithm.2.1}{}}
\newlabel{eq:8.12}{{2-25}{20}{\glsentrytext {SGD}优化算法}{equation.2.25}{}}
\newlabel{eq:8.13}{{2-26}{20}{\glsentrytext {SGD}优化算法}{equation.2.26}{}}
\newlabel{eq:8.14}{{2-27}{20}{\glsentrytext {SGD}优化算法}{equation.2.27}{}}
\citation{Hinton-ipam2012}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}RMSProp优化算法}{21}{subsection.2.7.2}}
\newlabel{sec:rmsprop}{{2.7.2}{21}{RMSProp优化算法}{subsection.2.7.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.2}{\ignorespaces RMSProp算法\relax }}{21}{algorithm.2.2}}
\newlabel{alg:rms_prop}{{2.2}{21}{RMSProp算法\relax }{algorithm.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Adam}{21}{subsection.2.7.3}}
\newlabel{sec:adam}{{2.7.3}{21}{Adam}{subsection.2.7.3}{}}
\citation{Schaul2014_unittests}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2.3}{\ignorespaces Adam算法\relax }}{22}{algorithm.2.3}}
\newlabel{alg:adam}{{2.3}{22}{Adam算法\relax }{algorithm.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.4}选择正确的优化算法}{22}{subsection.2.7.4}}
\newlabel{sec:choosing_the_right_optimization_algorithms}{{2.7.4}{22}{选择正确的优化算法}{subsection.2.7.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}本章小结}{22}{section.2.8}}
\@setckpt{chapters/chapter2}{
\setcounter{page}{23}
\setcounter{equation}{27}
\setcounter{enumi}{0}
\setcounter{enumii}{0}
\setcounter{enumiii}{0}
\setcounter{enumiv}{0}
\setcounter{footnote}{0}
\setcounter{mpfootnote}{0}
\setcounter{part}{0}
\setcounter{chapter}{2}
\setcounter{section}{8}
\setcounter{subsection}{0}
\setcounter{subsubsection}{0}
\setcounter{paragraph}{0}
\setcounter{subparagraph}{0}
\setcounter{figure}{6}
\setcounter{table}{0}
\setcounter{lofdepth}{1}
\setcounter{lotdepth}{1}
\setcounter{ContinuedFloat}{0}
\setcounter{NAT@ctr}{0}
\setcounter{Item}{0}
\setcounter{Hfootnote}{0}
\setcounter{Hy@AnnotLevel}{0}
\setcounter{bookmark@seq@number}{39}
\setcounter{XDU@counter@resumelistcounter}{0}
\setcounter{KVtest}{1}
\setcounter{subfigure}{0}
\setcounter{subfigure@save}{0}
\setcounter{subtable}{0}
\setcounter{subtable@save}{0}
\setcounter{parentequation}{0}
\setcounter{float@type}{8}
\setcounter{algorithm}{3}
\setcounter{ALC@unique}{26}
\setcounter{ALC@line}{13}
\setcounter{ALC@rem}{13}
\setcounter{ALC@depth}{0}
\setcounter{su@anzahl}{0}
\setcounter{LT@tables}{0}
\setcounter{LT@chunks}{0}
\setcounter{section@level}{1}
}
